{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06fb921b",
   "metadata": {},
   "source": [
    "# Sentiment analysis for Hindi/English code-mixed text.\n",
    "### CS521 - Project | Spring'23\n",
    "<hr/>\n",
    "\n",
    "#### Code to train & evaluate BiLSTM & Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd268c",
   "metadata": {
    "id": "d2bd268c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Embedding ,Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69f186",
   "metadata": {
    "id": "bf69f186"
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('train_data_clean.csv')\n",
    "x=d['Sentence']\n",
    "y=d['Label']\n",
    "y=list(y)\n",
    "x=list(x)\n",
    "for i in range(len(y)):\n",
    "    if y[i]=='negative':\n",
    "        y[i] = 0\n",
    "    elif y[i]=='neutral':\n",
    "        y[i] = 1\n",
    "    elif y[i]=='positive':\n",
    "        y[i] = 2\n",
    "y=np.array(y)\n",
    "\n",
    "\n",
    "v = pd.read_csv('validate_data_clean.csv')\n",
    "vx=v['Sentence']\n",
    "vy=v['Label']\n",
    "vy=list(vy)\n",
    "vx=list(vx)\n",
    "for i in range(len(vy)):\n",
    "  for i in range(len(vy)):\n",
    "    if vy[i]=='negative':\n",
    "        vy[i] = 0\n",
    "    elif vy[i]=='neutral':\n",
    "        vy[i] = 1\n",
    "    elif vy[i]=='positive':\n",
    "        vy[i] = 2\n",
    "vy=np.array(vy)\n",
    "\n",
    "\n",
    "t = pd.read_csv('test_data_clean.csv')\n",
    "tx=list(t['Sentence'])\n",
    "\n",
    "ty = pd.read_csv('test_labels.csv')\n",
    "sentiment = []\n",
    "ty = ty['Label']\n",
    "for i in range(len(ty)):\n",
    "    if ty[i]=='negative':\n",
    "        sentiment.append(0)\n",
    "    elif ty[i]=='neutral':\n",
    "        sentiment.append(1)\n",
    "    elif ty[i]=='positive':\n",
    "        sentiment.append(2)\n",
    "ty = np.array(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0cc70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessed train data\n",
    "df_train = pd.read_csv('data/final_data/train_data_clean.csv')\n",
    "x_train=df_train['Sentence']\n",
    "y_train=df_train['Label']\n",
    "y=list(y_train)\n",
    "x=list(x_train)\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]=='negative':\n",
    "        y_train[i] = 0\n",
    "    elif y_train[i]=='neutral':\n",
    "        y_train[i] = 1\n",
    "    elif y_train[i]=='positive':\n",
    "        y_train[i] = 2\n",
    "y=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66542d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessed validate data\n",
    "df_v = pd.read_csv('data/final_data/validate_data_clean.csv')\n",
    "vx=df_v['Sentence']\n",
    "vy=df_v['Label']\n",
    "vy=list(vy)\n",
    "vx=list(vx)\n",
    "for i in range(len(vy)):\n",
    "  for i in range(len(vy)):\n",
    "    if vy[i]=='negative':\n",
    "        vy[i] = 0\n",
    "    elif vy[i]=='neutral':\n",
    "        vy[i] = 1\n",
    "    elif vy[i]=='positive':\n",
    "        vy[i] = 2\n",
    "vy=np.array(vy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d2c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessed test data\n",
    "t = pd.read_csv('data/final_data/test_data_clean.csv')\n",
    "tx=list(t['Sentence'])\n",
    "\n",
    "ty = pd.read_csv('data/final_data/test_labels.csv')\n",
    "sentiment = []\n",
    "ty = \n",
    "for i in range(len(ty)):\n",
    "    if ty[i][1]=='negative':\n",
    "        sentiment.append(0)\n",
    "    elif ty[i][1]=='neutral':\n",
    "        sentiment.append(1)\n",
    "    elif ty[i][1]=='positive':\n",
    "        sentiment.append(2)\n",
    "ty = np.array(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4203b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "tokenizer = Tokenizer(num_words=2500,split=' ')\n",
    "tokenizer.fit_on_texts(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert to Sequences\n",
    "X= tokenizer.texts_to_sequences(x)\n",
    "X = pad_sequences(X,maxlen=50)\n",
    "\n",
    "VX= tokenizer.texts_to_sequences(vx)\n",
    "VX = pad_sequences(VX,maxlen=50)\n",
    "\n",
    "\n",
    "TX = tokenizer.texts_to_sequences(tx)\n",
    "TX = pad_sequences(TX,maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 20000\n",
    "embed_size = 128\n",
    "\n",
    "# Model\n",
    "inputs = tf.keras.Input(shape=(X.shape[1]))\n",
    "embd = Embedding(vocab_size, embed_size,trainable=True)(inputs)\n",
    "x_lstmConv = Bidirectional(LSTM(128,activation='tanh', return_sequences=True, dropout=0.15, recurrent_dropout=0.15))(embd)\n",
    "x_lstmConv = tf.keras.layers.Conv1D(64, kernel_size=3, padding='valid', kernel_initializer='glorot_uniform')(x_lstmConv)\n",
    "avg_pool = tf.keras.layers.GlobalAveragePooling1D()(x_lstmConv)\n",
    "max_pool = tf.keras.layers.GlobalMaxPool1D()(x_lstmConv)\n",
    "x_lstmConv = tf.keras.layers.concatenate([avg_pool, max_pool])\n",
    "x_lstmConv = Dense(3, activation='softmax')(x_lstmConv)\n",
    "biLstm = tf.keras.Model(inputs = inputs , outputs = x)\n",
    "biLstm.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07), metrics=['accuracy'])\n",
    "fittingLSTM = biLstm.fit(X, y, epochs=7, batch_size=128,verbose=2,validation_data=(VX,vy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa6e40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bfa6e40",
    "outputId": "d3896a74-9c53-4624-d9ce-3cb474f69dc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "110/110 - 50s - loss: 0.9330 - accuracy: 0.5453 - val_loss: 0.8670 - val_accuracy: 0.5893 - 50s/epoch - 456ms/step\n",
      "Epoch 2/7\n",
      "110/110 - 37s - loss: 0.7909 - accuracy: 0.6449 - val_loss: 0.8616 - val_accuracy: 0.6000 - 37s/epoch - 340ms/step\n",
      "Epoch 3/7\n",
      "110/110 - 37s - loss: 0.7323 - accuracy: 0.6779 - val_loss: 0.9286 - val_accuracy: 0.5817 - 37s/epoch - 340ms/step\n",
      "Epoch 4/7\n",
      "110/110 - 36s - loss: 0.6687 - accuracy: 0.7130 - val_loss: 0.9370 - val_accuracy: 0.5807 - 36s/epoch - 327ms/step\n",
      "Epoch 5/7\n",
      "110/110 - 36s - loss: 0.5840 - accuracy: 0.7581 - val_loss: 1.0688 - val_accuracy: 0.5730 - 36s/epoch - 323ms/step\n",
      "Epoch 6/7\n",
      "110/110 - 36s - loss: 0.4645 - accuracy: 0.8181 - val_loss: 1.2443 - val_accuracy: 0.5573 - 36s/epoch - 329ms/step\n",
      "Epoch 7/7\n",
      "110/110 - 36s - loss: 0.4018 - accuracy: 0.8416 - val_loss: 1.3684 - val_accuracy: 0.5493 - 36s/epoch - 326ms/step\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 1.1394 - accuracy: 0.5870\n",
      "Test accuracy of BiLSTM model = 0.5870000123977661\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Results\n",
    "test_loss, test_acc = bi.evaluate(TX,ty)\n",
    "print(\"Test accuracy of BiLSTM model = \" + str(test_acc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e7948",
   "metadata": {
    "id": "I4qmfs5reCgy"
   },
   "source": [
    "# Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tzR5mfo5eDwv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzR5mfo5eDwv",
    "outputId": "c0d9e934-ff05-4d91-8784-38c21961eddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "110/110 - 14s - loss: 0.9395 - accuracy: 0.5284 - val_loss: 0.8539 - val_accuracy: 0.6123 - 14s/epoch - 125ms/step\n",
      "Epoch 2/6\n",
      "110/110 - 4s - loss: 0.7945 - accuracy: 0.6448 - val_loss: 0.8782 - val_accuracy: 0.5840 - 4s/epoch - 33ms/step\n",
      "Epoch 3/6\n",
      "110/110 - 3s - loss: 0.7383 - accuracy: 0.6768 - val_loss: 0.9043 - val_accuracy: 0.5847 - 3s/epoch - 30ms/step\n",
      "Epoch 4/6\n",
      "110/110 - 1s - loss: 0.6930 - accuracy: 0.6992 - val_loss: 0.9251 - val_accuracy: 0.5843 - 1s/epoch - 13ms/step\n",
      "Epoch 5/6\n",
      "110/110 - 2s - loss: 0.6432 - accuracy: 0.7273 - val_loss: 1.0038 - val_accuracy: 0.5587 - 2s/epoch - 14ms/step\n",
      "Epoch 6/6\n",
      "110/110 - 1s - loss: 0.5980 - accuracy: 0.7454 - val_loss: 1.0376 - val_accuracy: 0.5683 - 1s/epoch - 10ms/step\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embed_size, input_shape = (X.shape[1],)))\n",
    "model.add(LSTM(units=264, activation='tanh'))\n",
    "model.add(Dense(units=64,activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics = ['accuracy'])\n",
    "history = model.fit(X, y, epochs=6, batch_size=128,verbose=2,validation_data=(VX,vy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y6DDzD74ffGv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6DDzD74ffGv",
    "outputId": "62120e2e-7945-4295-f50f-876b7728fd32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 3ms/step - loss: 0.9009 - accuracy: 0.6003\n",
      "Test accuracy = 0.6003333330154419\n"
     ]
    }
   ],
   "source": [
    "# Test Results\n",
    "test_loss, test_acc = model.evaluate(TX,ty)\n",
    "print(\"Test accuracy = \" + str(test_acc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IKD5pcetgGJr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKD5pcetgGJr",
    "outputId": "a911b5de-c549-4aac-d440-30d6ad3769cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 3s 31ms/step\n",
      "94/94 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "x1 = bi.predict(TX)\n",
    "x2 = model.predict(TX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oNfDrp3igNWQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNfDrp3igNWQ",
    "outputId": "7de67854-d44f-4d16-a957-94ce625a35df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 3s 31ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "x3 = bi.predict(VX)\n",
    "x4 = model.predict(VX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kUJ-90GwgUng",
   "metadata": {
    "id": "kUJ-90GwgUng"
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i in range(len(x1)):\n",
    "  b=[]\n",
    "  for j in range(len(x1[i])):\n",
    "    z = max(x1[i][j],x2[i][j] )\n",
    "    b.append(z)\n",
    "  a.append(b)\n",
    "  b=[]\n",
    "\n",
    "c=[]\n",
    "for i in range(len(x3)):\n",
    "  d=[]\n",
    "  for j in range(len(x3[i])):\n",
    "    z = max(x3[i][j],x4[i][j] )\n",
    "    d.append(z)\n",
    "  c.append(d)\n",
    "  d=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vikheINJg9s4",
   "metadata": {
    "id": "vikheINJg9s4"
   },
   "outputs": [],
   "source": [
    "a=np.array(a)\n",
    "a=np.argmax(a,axis=1)\n",
    "c=np.array(c)\n",
    "c=np.argmax(c,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AX8nJcSShHG_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AX8nJcSShHG_",
    "outputId": "129b1ee7-74cd-4634-8da8-7135568e90b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy acieved is 0.6096666666666667\n"
     ]
    }
   ],
   "source": [
    "# Testing the accuracy on the test data provided.\n",
    "acuracy_test = accuracy_score(ty,a)\n",
    "print(\"Accuracy acieved is \" + str(test_acc) )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
